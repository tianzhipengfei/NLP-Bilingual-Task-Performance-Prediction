{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MF():\n",
    "\n",
    "    def __init__(self, R, K, alpha, beta, iterations, test_samples, X=None, Y=None, Z=None, src_si_len=0, \\\n",
    "                 tgt_si_len=0, lang_pair_si_len=0, src_index=None, tgt_index=None, model=None, num_running=0):\n",
    "        \"\"\"\n",
    "        Perform matrix factorization to predict empty\n",
    "        entries in a matrix.\n",
    "\n",
    "        Arguments\n",
    "        - R (ndarray)                  : src-tgt language rating matrix\n",
    "        - K (int)                      : number of latent dimensions\n",
    "        - alpha (float)                : learning rate\n",
    "        - beta (float)                 : regularization parameter\n",
    "        - X (dict)                     : source language side information\n",
    "        - Y (dict)                     : target language side information\n",
    "        - Z (dict)                     : language pair side information\n",
    "        - src_si_len(int)              : source language side information length\n",
    "        - tgt_si_len(int)              : target language side information length\n",
    "        - lang_pair_si_len(int)        : language pair side information length\n",
    "        \"\"\"\n",
    "\n",
    "        self.R = np.array(R)\n",
    "        self.Prediction = deepcopy(self.R)\n",
    "        self.src_langs = R.index.tolist()\n",
    "        self.tgt_langs = R.columns.tolist()\n",
    "        self.num_src, self.num_tgt = R.shape\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.iterations = iterations\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.Z = Z\n",
    "        self.src_si_len = src_si_len\n",
    "        self.tgt_si_len = tgt_si_len\n",
    "        self.lang_pair_si_len = lang_pair_si_len\n",
    "        self.test_samples = test_samples\n",
    "        self.src_index=src_index \n",
    "        self.tgt_index=tgt_index\n",
    "        self.model=model\n",
    "        self.num_running = num_running\n",
    "        self.score_dict = {'BLEU': \"WIKI-MT\", \"Muse\": \"BLI-Muse\", \"Vecmap\": \"BLI-Vecmap\"}\n",
    "        self.traing_error_log=[]\n",
    "        self.test_error_log=[]\n",
    "        \n",
    "\n",
    "    def train(self):\n",
    "        # Initialize user and item latent feature matrice\n",
    "        self.P = np.random.normal(scale=1./self.K, size=(self.num_src, self.K))\n",
    "        self.Q = np.random.normal(scale=1./self.K, size=(self.num_tgt, self.K))\n",
    "\n",
    "        # Initialize side information's parameter if necesary\n",
    "        if self.X and self.src_si_len:\n",
    "            self.A = np.random.normal(scale = 1./self.src_si_len, size=self.src_si_len)\n",
    "        if self.Y and self.tgt_si_len:\n",
    "            self.B = np.random.normal(scale = 1./self.tgt_si_len, size=self.tgt_si_len)\n",
    "        if self.Z and self.lang_pair_si_len:\n",
    "            self.C = np.random.normal(scale = 1./self.lang_pair_si_len, size=self.lang_pair_si_len)\n",
    "        \n",
    "        # Initialize the biases\n",
    "        # the biases of users and items are initilized as 0\n",
    "        # the bias of rating is initilized as mean value\n",
    "        self.b_u = np.zeros(self.num_src)\n",
    "        self.b_i = np.zeros(self.num_tgt)\n",
    "        self.b = np.mean(self.R[np.where(self.R != 0)])\n",
    "\n",
    "        # Create a list of training samples (where rating > 0)\n",
    "        self.samples = []\n",
    "        for i in range(self.num_src):\n",
    "            for j in range(self.num_tgt):\n",
    "                if self.R[i,j] > 0:\n",
    "                    cur_tuple = [i, j, self.R[i, j]]\n",
    "                    src_lang = self.src_langs[i]\n",
    "                    tgt_lang = self.tgt_langs[j]\n",
    "                    if self.X:\n",
    "                        if src_lang in self.X.keys():\n",
    "                            cur_tuple.append(self.X[src_lang])\n",
    "                        else:\n",
    "                            raise KeyError\n",
    "                    if self.Y:\n",
    "                        if tgt_lang in self.Y.keys():\n",
    "                            cur_tuple.append(self.Y[src_lang])\n",
    "                        else:\n",
    "                            raise KeyError\n",
    "                    if self.Z:\n",
    "                        if src_lang + \"_\" + tgt_lang in self.Z.keys():\n",
    "                            cur_tuple.append(self.Z[src_lang + \"_\" + tgt_lang])\n",
    "                        else:\n",
    "                            raise KeyError\n",
    "                    self.samples.append(tuple(cur_tuple))\n",
    "\n",
    "        # Perform stochastic gradient descent for number of iterations\n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            # shuffle training samples\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            mse = self.mse()\n",
    "            training_process.append((i, mse))\n",
    "            if (i+1) % 100 == 0:\n",
    "                self.traing_error_log.append((i, mse))\n",
    "                test_mse = self.evaluate_testing(self.test_samples, self.src_index, self.tgt_index, self.model)\n",
    "                self.test_error_log.append((i, test_mse))\n",
    "#                 print(\"\\t\\tIteration: %d ; error = %.4f\" % (i+1, mse))\n",
    "\n",
    "        return training_process\n",
    "\n",
    "    def mse(self):\n",
    "        \"\"\"\n",
    "        A function to compute the total mean square error\n",
    "        \"\"\"\n",
    "        xs, ys = self.R.nonzero()\n",
    "#         predicted = self.full_matrix()\n",
    "        error = 0\n",
    "        for x, y in zip(xs, ys):\n",
    "            error += pow(self.R[x][y] - self.Prediction[x][y], 2)\n",
    "        return np.sqrt(error / len(xs))\n",
    "\n",
    "    def sgd(self):\n",
    "        \"\"\"\n",
    "        Perform stochastic graident descent\n",
    "        \"\"\"\n",
    "        for sample in self.samples:\n",
    "            i, j, r = sample[0], sample[1], sample[2]\n",
    "            # Computer prediction and error\n",
    "            prediction = self.get_rating(sample)\n",
    "            self.Prediction[i][j] = prediction\n",
    "            e = (r - prediction)\n",
    "\n",
    "            # Update biases\n",
    "            self.b_u[i] += self.alpha * (e - self.beta * self.b_u[i])\n",
    "            self.b_i[j] += self.alpha * (e - self.beta * self.b_i[j])\n",
    "\n",
    "            # Update user and item latent feature matrices\n",
    "            self.P[i, :] += self.alpha * (e * self.Q[j, :] - self.beta * self.P[i,:])\n",
    "            self.Q[j, :] += self.alpha * (e * self.P[i, :] - self.beta * self.Q[j,:])\n",
    "            \n",
    "            # Update side information parameter if necessary\n",
    "            cur_index = 3\n",
    "            if self.X:\n",
    "                x = np.array(sample[cur_index], dtype=np.float64)\n",
    "                cur_index += 1\n",
    "                self.A += self.alpha * (e * x - self.beta * self.A)\n",
    "            if self.Y:\n",
    "                y = np.array(sample[cur_index], dtype=np.float64)\n",
    "                cur_index += 1\n",
    "                self.B += self.alpha * (e * y - self.beta * self.B)\n",
    "            if self.Z:\n",
    "                z = np.array(sample[cur_index], dtype=np.float64)\n",
    "                self.C += self.alpha * (e * z - self.beta * self.C)\n",
    "                \n",
    "\n",
    "    def get_rating(self, sample):\n",
    "        \"\"\"\n",
    "        Get the predicted rating of sample\n",
    "        \"\"\"\n",
    "        i, j, r = sample[0], sample[1], sample[2]\n",
    "        prediction = self.b + self.b_u[i] + self.b_i[j] + self.P[i, :].dot(self.Q[j, :].T)\n",
    "        cur_index = 3\n",
    "        if self.X:\n",
    "            x = sample[cur_index]\n",
    "            cur_index += 1\n",
    "            prediction += self.A.dot(x.T)\n",
    "        if self.Y:\n",
    "            y = sample[cur_index]\n",
    "            cur_index += 1\n",
    "            prediction += self.B.dot(y.T)\n",
    "        if self.Z:\n",
    "            z = sample[cur_index]\n",
    "            prediction += self.C.dot(z.T)\n",
    "        return prediction\n",
    "    \n",
    "    def evaluate_testing(self, test_data, src_index_name, tgt_index_name, score_index_name):\n",
    "        \"\"\"\n",
    "        Predict the score for testing data\n",
    "        \"\"\" \n",
    "        rmse = 0.0\n",
    "        for record in test_data.iterrows():\n",
    "            record = record[1]\n",
    "            src_lang = record[src_index_name]\n",
    "            tgt_lang = record[tgt_index_name]\n",
    "            src_lang_index = self.src_langs.index(src_lang)\n",
    "            tgt_lang_index = self.tgt_langs.index(tgt_lang)\n",
    "            score = record[score_index_name]\n",
    "            cur_tuple = [src_lang_index, tgt_lang_index, score]\n",
    "            if self.X:\n",
    "                if src_lang in self.X.keys():\n",
    "                    cur_tuple.append(self.X[src_lang])\n",
    "                else:\n",
    "                    raise KeyError\n",
    "            if self.Y:\n",
    "                if tgt_lang in self.Y.keys():\n",
    "                    cur_tuple.append(self.Y[src_lang])\n",
    "                else:\n",
    "                    raise KeyError\n",
    "            if self.Z:\n",
    "                if src_lang + \"_\" + tgt_lang in self.Z.keys():\n",
    "                    cur_tuple.append(self.Z[src_lang + \"_\" + tgt_lang])\n",
    "                else:\n",
    "                    raise KeyError\n",
    "            prediction = self.get_rating(tuple(cur_tuple))\n",
    "            rmse += (prediction - score) * (prediction - score)\n",
    "        return np.sqrt(rmse / len(test_data))\n",
    "        \n",
    "\n",
    "    def full_matrix(self):\n",
    "        \"\"\"\n",
    "        Computer the full matrix using the resultant biases, P, Q, A, B, and C\n",
    "        \"\"\"\n",
    "        res = deepcopy(self.R)\n",
    "        for i in range(self.num_src):\n",
    "            for j in range(self.num_tgt):\n",
    "                src_lang = self.src_langs[i]\n",
    "                tgt_lang = self.tgt_langs[j]\n",
    "                res[i][j] = self.b + self.b_u[i] + self.b_i[j] + self.P[i, :].dot(self.Q[j, :].T)\n",
    "                if self.X and src_lang in self.X.keys():\n",
    "                    x = self.X[src_lang]\n",
    "                    res[i][j] += self.A.dot(x.T)\n",
    "                if self.Y and tgt_lang in self.Y.keys():\n",
    "                    y = self.X[tgt_lang]\n",
    "                    res[i][j] += self.A.dot(x.T)\n",
    "                if self.Z and src_lang + \"_\" + tgt_lang in self.Z.keys():\n",
    "                    z = self.X[src_lang + \"_\" + tgt_lang]\n",
    "                    res[i][j] += self.A.dot(x.T)\n",
    "        return self.b + self.b_u[:,np.newaxis] + self.b_i[np.newaxis:,] + self.P.dot(self.Q.T)\n",
    "    \n",
    "    def draw_error_curve(self, i):\n",
    "        import matplotlib.pyplot as plt\n",
    "        import numpy as np\n",
    "        iters = []\n",
    "        train_loss = []\n",
    "        test_loss = []\n",
    "        for item in self.traing_error_log:\n",
    "            iters.append(item[0])\n",
    "            train_loss.append(item[1])\n",
    "        for item in self.test_error_log:\n",
    "            test_loss.append(item[1])\n",
    "\n",
    "        plt.plot(iters, train_loss, 'b', label='train loss')#'b'指：color='blue'\n",
    "        plt.plot(iters, test_loss, 'r', label='test loss')#'r'指：color='red'\n",
    "\n",
    "        plt.legend()  #显示上面的label\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Loss')\n",
    "        title = self.score_dict[self.model] + \"_\" + str(self.num_running+1) + \"_Fold\" + str(i+1)\n",
    "        plt.title(title) \n",
    "        plt.savefig(\"../result/within_pair_si/\" + self.score_dict[self.model] + \"/fold\" + str(i+1) + \"/\" + title + \".png\")\n",
    "\n",
    "        #plt.ylim(-1,1)#仅设置y轴坐标范围\n",
    "        plt.show()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Represent the two tasks above as matrices (BLEU scores for Wiki-MT and Accuracy for BLI) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import random as rd\n",
    "\n",
    "def split_k_fold_data(file_dir, score_index_name, src_index_name, tgt_index_name, k=5):\n",
    "    data = pd.read_csv(file_dir)\n",
    "    \n",
    "    # shuffle\n",
    "    data = data.sample(frac=1)\n",
    "    \n",
    "    # generate score matrix\n",
    "    src_langs = data[src_index_name].unique()\n",
    "    tgt_langs = data[tgt_index_name].unique()\n",
    "    score_matrix = pd.DataFrame(index = src_langs, columns = tgt_langs)\n",
    "    \n",
    "    # eliminate empty rows and columns\n",
    "    data = data.dropna(axis=1, how=\"all\")\n",
    "    data = data.dropna(axis=0, how=\"all\")\n",
    "    \n",
    "    # K fold split\n",
    "    k_fold_data = {}\n",
    "    models = list(score_index_name)\n",
    "    lens= len(data)\n",
    "    \n",
    "    for i, model in enumerate(models):\n",
    "        ex_per_fold = int(np.ceil(lens / k))\n",
    "        for j in range(k):\n",
    "            start = ex_per_fold * j\n",
    "            end = ex_per_fold * (j + 1)\n",
    "            if j == 0:\n",
    "                k_fold_data[model] = {\"train\": [], \"test\": []}\n",
    "            k_fold_data[model][\"train\"].append(pd.concat([data.iloc[:start, :], data.iloc[end:, :]], axis=0))\n",
    "            k_fold_data[model][\"test\"].append(data.iloc[start:end, :])\n",
    "    return k_fold_data, score_matrix\n",
    "\n",
    "def generate_score_matrix(train_data, src_index_name, tgt_index_name, score_index_name, origin_score_matrix):    \n",
    "    score_matrix = deepcopy(origin_score_matrix)\n",
    "    \n",
    "    for record in train_data.iterrows():\n",
    "        record = record[1]\n",
    "        src_lang = record[src_index_name]\n",
    "        tgt_lang = record[tgt_index_name]\n",
    "        score = record[score_index_name]\n",
    "        score_matrix.loc[src_lang, tgt_lang] = score\n",
    "#         score_matrix[src_lang][tgt_lang] = score\n",
    "    print(score_matrix.columns)\n",
    "    for lang in score_matrix.columns:\n",
    "        score_matrix[lang][lang] = 100.0\n",
    "    score_matrix.fillna(0, inplace=True)\n",
    "    print(score_matrix)\n",
    "    return score_matrix\n",
    "\n",
    "def get_rmse(valid_data, model, src_index_name, tgt_index_name, score_matrix, train_matrix):\n",
    "    rmse = 0.0\n",
    "    src_langs = train_matrix.index.tolist()\n",
    "    tgt_langs = train_matrix.columns.tolist()\n",
    "    for cur_valid_data in valid_data.iterrows():\n",
    "        cur_valid_data = cur_valid_data[1]\n",
    "        src_lang, tgt_lang, score = cur_valid_data[src_index_name], cur_valid_data[tgt_index_name], cur_valid_data[model]\n",
    "        src_idx = src_langs.index(src_lang)\n",
    "        tgt_idx = tgt_langs.index(tgt_lang)\n",
    "        prediction = score_matrix[src_idx][tgt_idx]\n",
    "        rmse += (prediction - score) * (prediction - score)\n",
    "    return np.sqrt(rmse / len(valid_data))\n",
    "\n",
    "def get_result(alpha, beta, data_dir, scores, src_index, tgt_index, k, num_running, src_lang_side_info=None, \\\n",
    "               tgt_lang_side_info=None, lang_pair_side_info=None, src_si_len=0, tgt_si_len=0, \\\n",
    "               lang_pair_si_len=0):\n",
    "    all_running_rmse = 0.0\n",
    "    for nr in range(num_running):\n",
    "        print(\"num running: \" + str(nr+1))\n",
    "        data, langs_matrix = split_k_fold_data(data_dir, scores, src_index, tgt_index, k)\n",
    "        res = {}\n",
    "        for model in scores:\n",
    "            print(\"-\"*40)\n",
    "            print(model)\n",
    "            total_rmse = 0.0\n",
    "            for i in range(k):\n",
    "                print(\"\\tFold {}: \".format(i+1))\n",
    "                train_data, test_data = data[model][\"train\"][i], data[model][\"test\"][i]\n",
    "                train_matrix = generate_score_matrix(train_data, src_index, tgt_index, model, langs_matrix)\n",
    "                mf = MF(train_matrix, K=2, alpha=alpha, beta=beta, iterations=2000, test_samples=test_data, X=src_lang_side_info, \\\n",
    "                        Y=tgt_lang_side_info, Z=lang_pair_side_info, src_si_len=src_si_len, tgt_si_len=tgt_si_len, \\\n",
    "                        lang_pair_si_len=lang_pair_si_len, src_index=src_index, tgt_index=tgt_index, model=model, \\\n",
    "                       num_running=nr)\n",
    "                trainging_log = mf.train()\n",
    "#                 predictions = mf.full_matrix()\n",
    "#                 cur_rmse = get_rmse(test_data, model, src_index, tgt_index, predictions, train_matrix)\n",
    "                cur_rmse = mf.evaluate_testing(test_data, src_index, tgt_index, model)\n",
    "                mf.draw_error_curve(i)\n",
    "                total_rmse += cur_rmse\n",
    "                print(\"\\t\\trmse is {}.\".format(cur_rmse))\n",
    "                print(\"*\" * 20)\n",
    "                \n",
    "            average_rmse = total_rmse / k\n",
    "            print(\"average rmse: \" + str(average_rmse))\n",
    "            res[model] = average_rmse\n",
    "        res_rmse = 0.0\n",
    "        for key, value in res.items():\n",
    "            res_rmse += value\n",
    "        all_running_rmse += res_rmse / len(scores)\n",
    "    return all_running_rmse / num_running\n",
    "\n",
    "def get_language_pair_side_info(data_dir, side_info_features, src_lang_name, tgt_lang_name):\n",
    "    data = pd.read_csv(data_dir)\n",
    "    side_dict = {}\n",
    "    for record in data.iterrows():\n",
    "        record = record[1]\n",
    "        src_lang = record[src_lang_name]\n",
    "        tgt_lang = record[tgt_lang_name]\n",
    "        side_dict[src_lang + \"_\" + tgt_lang] = record[side_info_features].values\n",
    "    return side_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num running: 1\n",
      "----------------------------------------\n",
      "BLEU\n",
      "\tFold 1: \n",
      "Index(['glg', 'ces', 'nld', 'fra', 'slv', 'bul', 'spa', 'cmn', 'heb', 'pol',\n",
      "       'vie', 'ind', 'bos', 'ita', 'dan', 'hrv', 'zh-tw', 'ron', 'hun', 'srp',\n",
      "       'slk', 'fr-ca', 'tur', 'eng', 'por', 'swe', 'ara', 'pt-br', 'deu',\n",
      "       'rus', 'ukr', 'epo', 'nob', 'ell', 'eus', 'kor', 'mkd', 'jpn', 'hin',\n",
      "       'fin', 'est', 'fas', 'mar', 'lit'],\n",
      "      dtype='object')\n",
      "         glg    ces    nld    fra    slv    bul    spa    cmn    heb    pol  \\\n",
      "ara      0.0    0.0    0.0   12.2    2.7    4.9   13.2    8.2    0.0    3.0   \n",
      "cmn      3.2    2.2    0.0    7.6    2.4    3.2    8.2  100.0    0.0    2.2   \n",
      "spa     30.1    8.0   14.1    0.0    0.0   14.3  100.0    0.0    8.1    0.0   \n",
      "pol      5.2    8.2    6.2   11.3    0.0    7.4    0.0    6.3    2.3  100.0   \n",
      "bos      5.7    4.1    3.8    0.0   10.4    0.0    9.9    2.8    0.0    0.0   \n",
      "nld      7.3    5.9  100.0   16.7    5.1    8.2   16.8    0.0    3.9    0.0   \n",
      "por     23.0    8.0   14.9   26.7    8.1   15.2   32.4   12.9    0.0    0.0   \n",
      "heb      5.1    0.0    0.0   13.6    0.0    5.7   15.3    6.9  100.0    3.7   \n",
      "eng     24.3   15.5   25.1   32.6   16.5   23.9   35.8   18.0   17.3   12.0   \n",
      "mkd      5.4    5.4    6.7   11.5    7.1   18.2   15.2    0.0    4.0    0.0   \n",
      "fr-ca   18.1    7.8   15.1    0.0    0.0   12.5   23.7    0.0    6.8    0.0   \n",
      "dan      7.3    5.2   12.4   16.7    5.2    8.9   16.7    7.3    3.5    4.8   \n",
      "fra     17.2    8.3    0.0  100.0    0.0    0.0    0.0   11.1    6.8    0.0   \n",
      "kor      1.5    1.3    1.9    4.4    1.5    1.7    4.7    0.0    0.9    1.4   \n",
      "jpn      2.3    1.8    3.1    6.0    1.8    1.9    0.0    0.0    1.4    1.8   \n",
      "ita     19.3    6.9   12.8   24.9    7.1   11.7    0.0   10.7    6.2    0.0   \n",
      "glg    100.0    2.9    6.5   16.0    3.1    7.3    0.0    5.8    2.5    0.0   \n",
      "est      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "zh-tw    2.8    2.1    0.0    7.2    2.1    3.1    7.5    0.0    1.8    2.3   \n",
      "deu      6.8    8.1   17.6   18.3    8.6    0.0   17.4    0.0    0.0    6.8   \n",
      "epo     10.5    0.0    0.0   17.6    5.6    6.4    0.0    0.0    1.9    6.7   \n",
      "ron     10.0    5.1    0.0   19.3    5.0    9.7    0.0    7.8    4.0    5.2   \n",
      "ind      0.0    5.2    9.4   15.1    5.6    9.1   16.4    0.0    5.1    5.5   \n",
      "swe      0.0    0.0   11.5   15.7    4.7    7.4    0.0    7.8    3.3    5.8   \n",
      "hrv      5.7    7.0    0.0    0.0    0.0    8.7   12.6    4.8    1.5    5.4   \n",
      "ukr      5.5    7.4    0.0   14.1    0.0   12.3   14.2    7.9    3.5    9.6   \n",
      "srp      3.5    5.1    3.3    9.1    9.5    7.6   11.9    4.3    1.1    0.0   \n",
      "ces      5.0  100.0    0.0   11.4    6.7    7.8   12.6    0.0    2.5    0.0   \n",
      "ell     10.1    5.5    0.0   16.3    0.0   11.2    0.0    8.7    4.0    5.1   \n",
      "rus      6.0    0.0    8.1   14.5    0.0   12.6   14.3    9.1    4.9    8.9   \n",
      "slv      3.2    5.5    5.5    8.5  100.0    6.2   11.4    3.8    1.2    4.8   \n",
      "hun      3.9    0.0    6.0   10.9    4.2    5.6    0.0    0.0    2.1    4.3   \n",
      "tur      3.6    2.6    4.2    7.7    0.0    3.5    9.4    6.7    1.6    2.5   \n",
      "bul      0.0    6.7    7.7   14.7    0.0  100.0   16.3    6.4    3.2    6.3   \n",
      "nob      8.0    5.4    0.0   14.6    3.9    8.5   17.0    0.0    3.1    4.7   \n",
      "vie      6.5    0.0    7.3   13.2    4.6    7.5   13.7    9.9    4.6    4.5   \n",
      "pt-br   23.0    8.6   14.8    0.0    8.9    0.0   31.0   13.2    0.0    8.5   \n",
      "eus      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "slk      2.7   27.0    5.0    8.5    5.0    5.1    9.4    2.3    1.0    7.1   \n",
      "hin      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "fas      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "mar      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "lit      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "fin      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "\n",
      "       ...    eus    kor    mkd    jpn    hin    fin    est    fas    mar  \\\n",
      "ara    ...    0.0    5.3    0.0    4.2    0.0    0.0    0.0    0.0    0.0   \n",
      "cmn    ...    0.0    0.0    3.4    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "spa    ...    0.0    9.9   11.9    7.9    0.0    0.0    0.0    0.0    0.0   \n",
      "pol    ...    0.0    5.7    5.2    4.2    0.0    0.0    0.0    0.0    0.0   \n",
      "bos    ...    0.0    0.0   12.9    1.4    0.0    0.0    0.0    0.0    0.0   \n",
      "nld    ...    0.0    5.9    5.9    5.2    0.0    0.0    0.0    0.0    0.0   \n",
      "por    ...    0.0   10.6   13.1    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "heb    ...    0.0    4.5    4.6    4.1    0.0    0.0    0.0    0.0    0.0   \n",
      "eng    ...    0.0   18.6    0.0   10.2   21.9   10.9   14.3    8.8    3.5   \n",
      "mkd    ...    0.0    4.7  100.0    3.5    0.0    0.0    0.0    0.0    0.0   \n",
      "fr-ca  ...    0.0    8.8    0.0    7.5    0.0    0.0    0.0    0.0    0.0   \n",
      "dan    ...    0.0    6.0    6.2    4.7    0.0    0.0    0.0    0.0    0.0   \n",
      "fra    ...    0.0    8.7   10.7    7.3    0.0    0.0    0.0    0.0    0.0   \n",
      "kor    ...    0.0  100.0    1.2    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "jpn    ...    0.0   16.9    1.6  100.0    0.0    0.0    0.0    0.0    0.0   \n",
      "ita    ...    0.0    0.0    9.9    7.3    0.0    0.0    0.0    0.0    0.0   \n",
      "glg    ...    0.0    4.2    5.6    3.6    0.0    0.0    0.0    0.0    0.0   \n",
      "est    ...    0.0    0.0    0.0    0.0    0.0    0.0  100.0    0.0    0.0   \n",
      "zh-tw  ...    0.0    0.0    2.8    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "deu    ...    0.0    6.6    5.6    6.4    0.0    0.0    0.0    0.0    0.0   \n",
      "epo    ...    0.0    4.8    6.2    2.5    0.0    0.0    0.0    0.0    0.0   \n",
      "ron    ...    0.0    6.4    7.3    4.3    0.0    0.0    0.0    0.0    0.0   \n",
      "ind    ...    0.0    0.0    7.0    5.8    0.0    0.0    0.0    0.0    0.0   \n",
      "swe    ...    0.0    0.0    5.2    4.8    0.0    0.0    0.0    0.0    0.0   \n",
      "hrv    ...    0.0    4.0   14.1    1.8    0.0    0.0    0.0    0.0    0.0   \n",
      "ukr    ...    0.0    5.8    7.2    4.9    0.0    0.0    0.0    0.0    0.0   \n",
      "srp    ...    0.0    2.9   13.7    1.2    0.0    0.0    0.0    0.0    0.0   \n",
      "ces    ...    0.0    0.0    5.0    4.1    0.0    0.0    0.0    0.0    0.0   \n",
      "ell    ...    0.0    6.1   10.2    5.5    0.0    0.0    0.0    0.0    0.0   \n",
      "rus    ...    0.0    7.7    7.4    6.1    0.0    0.0    0.0    0.0    0.0   \n",
      "slv    ...    0.0    0.0    6.3    2.7    0.0    0.0    0.0    0.0    0.0   \n",
      "hun    ...    0.0    6.2    3.9    4.4    0.0    0.0    0.0    0.0    0.0   \n",
      "tur    ...    0.0    7.0    3.5    4.3    0.0    0.0    0.0    0.0    0.0   \n",
      "bul    ...    0.0    5.4    0.0    4.0    0.0    0.0    0.0    0.0    0.0   \n",
      "nob    ...    0.0    0.0    6.7    5.5    0.0    0.0    0.0    0.0    0.0   \n",
      "vie    ...    0.0    9.3    0.0    5.6    0.0    0.0    0.0    0.0    0.0   \n",
      "pt-br  ...    0.0   10.7    0.0    7.8    0.0    0.0    0.0    0.0    0.0   \n",
      "eus    ...  100.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "slk    ...    0.0    0.0    3.5    2.2    0.0    0.0    0.0    0.0    0.0   \n",
      "hin    ...    0.0    0.0    0.0    0.0  100.0    0.0    0.0    0.0    0.0   \n",
      "fas    ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0  100.0    0.0   \n",
      "mar    ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  100.0   \n",
      "lit    ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "fin    ...    0.0    0.0    0.0    0.0    0.0  100.0    0.0    0.0    0.0   \n",
      "\n",
      "         lit  \n",
      "ara      0.0  \n",
      "cmn      0.0  \n",
      "spa      0.0  \n",
      "pol      0.0  \n",
      "bos      0.0  \n",
      "nld      0.0  \n",
      "por      0.0  \n",
      "heb      0.0  \n",
      "eng     10.0  \n",
      "mkd      0.0  \n",
      "fr-ca    0.0  \n",
      "dan      0.0  \n",
      "fra      0.0  \n",
      "kor      0.0  \n",
      "jpn      0.0  \n",
      "ita      0.0  \n",
      "glg      0.0  \n",
      "est      0.0  \n",
      "zh-tw    0.0  \n",
      "deu      0.0  \n",
      "epo      0.0  \n",
      "ron      0.0  \n",
      "ind      0.0  \n",
      "swe      0.0  \n",
      "hrv      0.0  \n",
      "ukr      0.0  \n",
      "srp      0.0  \n",
      "ces      0.0  \n",
      "ell      0.0  \n",
      "rus      0.0  \n",
      "slv      0.0  \n",
      "hun      0.0  \n",
      "tur      0.0  \n",
      "bul      0.0  \n",
      "nob      0.0  \n",
      "vie      0.0  \n",
      "pt-br    0.0  \n",
      "eus      0.0  \n",
      "slk      0.0  \n",
      "hin      0.0  \n",
      "fas      0.0  \n",
      "mar      0.0  \n",
      "lit    100.0  \n",
      "fin      0.0  \n",
      "\n",
      "[44 rows x 44 columns]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-b0794917a3d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m wiki_result = get_result(WIKI_ALPHA, WIKI_BETA, WIKI_MT_DIR, WIKI_SCORE, WIKI_SRC, WIKI_TGT, k, num_running, \\\n\u001b[0;32m---> 25\u001b[0;31m                          lang_pair_side_info = WIKI_SIDE_INFO_DICT, lang_pair_si_len = 6)\n\u001b[0m\u001b[1;32m     26\u001b[0m bli_result = get_result(BLI_ALPHA, BLI_BETA, BLI_DIR, BLI_SCORE, BLI_SRC, BLI_TGT, k, num_running, \\\n\u001b[1;32m     27\u001b[0m                          lang_pair_side_info = BLI_SIDE_INFO_DICT, lang_pair_si_len = 6)\n",
      "\u001b[0;32m<ipython-input-12-6013a7a44df3>\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(alpha, beta, data_dir, scores, src_index, tgt_index, k, num_running, src_lang_side_info, tgt_lang_side_info, lang_pair_side_info, src_si_len, tgt_si_len, lang_pair_si_len)\u001b[0m\n\u001b[1;32m     84\u001b[0m                         \u001b[0mlang_pair_si_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlang_pair_si_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                        num_running=nr)\n\u001b[0;32m---> 86\u001b[0;31m                 \u001b[0mtrainging_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;31m#                 predictions = mf.full_matrix()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;31m#                 cur_rmse = get_rmse(test_data, model, src_index, tgt_index, predictions, train_matrix)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-c3142368aee0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     89\u001b[0m                             \u001b[0mcur_tuple\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msrc_lang\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtgt_lang\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_tuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "WIKI_MT_DIR = \"../data/data_wiki.csv\"\n",
    "WIKI_SRC = \"Source\"\n",
    "WIKI_TGT = \"Target\"\n",
    "WIKI_SCORE = [\"BLEU\"]\n",
    "WIKI_SIDE_FEATURES = ['geographic', 'genetic', 'inventory', 'syntactic', 'phonological', 'featural']\n",
    "WIKI_ALPHA = 0.0001\n",
    "WIKI_BETA = 0.0005\n",
    "\n",
    "BLI_DIR = \"../data/data_bli2.csv\"\n",
    "BLI_SRC = \"Source Language Code\"\n",
    "BLI_TGT = \"Target Language Code\"\n",
    "BLI_SCORE = [\"Muse\", \"Vecmap\"]\n",
    "BLI_SIDE_FEATURES = ['genetic', 'syntactic', 'featural', 'phonological', 'inventory', 'geographic']\n",
    "BLI_ALPHA = 0.0001\n",
    "BLI_BETA = 0.0005\n",
    "# The score metric is from \"NLPerf/src/task_feats.py\"\n",
    "\n",
    "k = 5\n",
    "num_running = 10\n",
    "\n",
    "WIKI_SIDE_INFO_DICT = get_language_pair_side_info(WIKI_MT_DIR, WIKI_SIDE_FEATURES, WIKI_SRC, WIKI_TGT)\n",
    "BLI_SIDE_INFO_DICT = get_language_pair_side_info(BLI_DIR, BLI_SIDE_FEATURES, BLI_SRC, BLI_TGT)\n",
    "\n",
    "wiki_result = get_result(WIKI_ALPHA, WIKI_BETA, WIKI_MT_DIR, WIKI_SCORE, WIKI_SRC, WIKI_TGT, k, num_running, \\\n",
    "                         lang_pair_side_info = WIKI_SIDE_INFO_DICT, lang_pair_si_len = 6)\n",
    "bli_result = get_result(BLI_ALPHA, BLI_BETA, BLI_DIR, BLI_SCORE, BLI_SRC, BLI_TGT, k, num_running, \\\n",
    "                         lang_pair_side_info = BLI_SIDE_INFO_DICT, lang_pair_si_len = 6)\n",
    "\n",
    "# wiki_mt_score_matrix = generate_score_matrix(WIKI_MT_DIR, \"Source\", \"Target\", \"BLEU\")\n",
    "# wiki_mt_score_matrix, wiki_mt_valid = generate_score_matrix(WIKI_MT_DIR, \"Source\", \"Target\", \"BLEU\")xdz\n",
    "# bli_score_matrix, bli_valid = generate_score_matrix(BLI_DIR, \"Source Language Code\", \"Target Language Code\", [\"Muse\", \"Vecmap\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wiki_result)\n",
    "print(bli_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
